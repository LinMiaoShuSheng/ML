{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.clip_by_value(t, clip_value_min, clip_value_max,name=None)\n",
    "# 使用tf.clip_by_value函数进行处理，并返回处理过的tensor\n",
    "\n",
    "# t：待处理的tensor，或是一个list等\n",
    "# clip_value_min：需要过滤的最小值，若t中存在比该值还小的值，一律换成clip_value_min\n",
    "# clip_value_max：需要过滤的最大值，若t中存在比该值还大的值，一律换成clip_value_max\n",
    "# name：名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Initial\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个list，填入一些数据\n",
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 4 5 6 7 7 7]\n",
      "[3 3 3 3 4 5 6 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "res = tf.clip_by_value(a,3,7)\n",
    "print(res.eval())\n",
    "print(sess.run(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.clip_by_global_norm 正则化的梯度修正，其目的也是修正梯度值，用于控制梯度爆炸的问题\n",
    "# def clip_by_global_norm(t_list, clip_norm, use_norm=None, name=None):\n",
    "#输入参数中：t_list为待修剪的张量, clip_norm 表示修剪比例(clipping ratio). \n",
    "#函数返回2个参数： list_clipped，修剪后的张量，以及global_norm，一个中间计算量。\n",
    "#计算公式\n",
    "# t_list[i] * clip_norm / max(global_norm, clip_norm)\n",
    "# global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))\n",
    "\n",
    "#示例：\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
    "grads = optimizer.compute_gradients(cost)\n",
    "for i, (g, v) in enumerate(grads):\n",
    "    if g is not None:\n",
    "        grads[i] = (tf.clip_by_norm(g, 5), v)  # clip gradients \n",
    "train_op = optimizer.apply_gradients(grads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
